Methodology behind school affordability Twitter data:

- Scraped as many of candidates recent Tweets as possible using t_scraper.py on January 12, 2019 (see twitters_found.txt and twitters_found2.txt for the text that I copy/pasted into the command line to perform the scrapes. Note: in making this file as I aggregate the data, I noticed that twitters_found2.txt incorrectly noted the data at which Hickenlooper handed one account over to his successor as governor--I corrected it and the error doesn't affect any data we ultimately used--see description below of how I removed the Tweets not made by Hickenlooper/in his name)

- Aggregated those tweets using command line - printed csv-style header to file using echo "[header]" > aggregated.csv, then combined Tweets cat *_tweets.csv >> aggregated.csv

-Manually deleted Tweets from Colorado governor Twitter account (labeled in aggregated file as Hickenlooper_office) that were posted after new governor took office and took over Twitter (did this on Jan 16, ~3 PM--see commit in sam-aff branch)

-For our MVP I analyzed the Tweets in R; in the spirit of experimentation and learning, for the second sprint I'm redoing the analysis in python

To filter for education-related Tweets, I ran the aggregated set of candidate Tweets through tweet_filter.py, which picks out Tweets containing education-related terms (see the script for the term list), then looks for words in those tweets related to college affordability in order to count the number of tweets by candidates about that issue.

That filter outputs a csv with the # of educational tweets by the candidate and the number of college affordability tweets.

